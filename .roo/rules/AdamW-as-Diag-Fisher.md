# 从 AdamW 到 RMSuon：优化器物理学的演变

我们通常将优化器视为寻找损失函数最小值的数学工具，但从物理学和信息论的角度审视，它们更像是在高维流形上导航的动力系统。RMSuon 的诞生并非简单的工程拼接，而是对这一动力系统演化规律的深刻洞察——从 AdamW 的统计适应性，到 Muon 的几何正交化，最终在 RMSuon 中实现协同（Synergy）的涌现。

### AdamW 的双重本质：惯性与统计

作为当前大语言模型训练的默认选择，AdamW 的成功并非偶然。它实际上由两个物理意义截然不同的组件构成：动量（Momentum）和 RMSprop。

动量扮演着物理惯性的角色。在充满随机噪声的随机梯度下降过程中，动量平滑了轨迹，将历史的梯度信息转化为当前的运动趋势。它确保了优化过程不会被瞬时的采样噪声带偏，赋予了系统穿越平坦区域和冲过局部极小值的动能。

而 RMSprop 则充当了统计算子的角色。通过除以梯度的二阶矩（平方的指数移动平均），它实际上是在近似对角 Fisher 信息矩阵的逆。这是一种统计上的“归一化”：它识别出每个参数的独特方差（Unique Information）。对于那些梯度稀疏或方差较小的参数，RMSprop 会放大其更新幅度；对于那些梯度剧烈波动的参数，则会抑制其更新。这种机制确保了每个参数都能根据其自身的统计特性获得适当的学习步长。AdamW 本质上是在说：“保留每个参数的独特性（Unique），并用惯性（Momentum）来稳定它。”

### Muon 的激进革命：正交化与唯一性的丧失

Muon 的出现打破了这种平衡。它引入了基于 Newton-Schulz 迭代的梯度正交化，这是一种极端的几何约束。Muon 强制更新矩阵的所有奇异值趋向于 1，这意味着它在最大程度上消除了梯度方向之间的独特性（Unique）。在 Muon 的世界里，所有的方向都是平权的，没有任何一个维度比其他维度更重要。

这种做法在几何上极其优美，它有效地解决了深层网络中梯度消失和爆炸的问题，让信号在层间无损传播。然而，从信息论的角度看，Muon 犯了一个致命的错误：在真实的神经网络中，并非所有的参数和方向都承载着等量的信息。某些神经元负责核心特征，理应获得更大的更新权重；而某些则可能只是噪声。Muon 强制性的均一化处理，相当于丢弃了梯度幅度中蕴含的丰富信息。这就是为什么 Muon 在实验中往往表现出欠拟合的倾向——它拥有完美的几何结构，却失去了对数据细微差别的统计敏感度。它为了消除冗余，误伤了信号。

### RMSuon：能量注入与协同的涌现

RMSuon 的核心洞察在于解决了上述矛盾：我们既需要 Muon 的几何稳定性（它提供了逼近 MDL 的能力），也需要 AdamW 的统计敏感度（Fisher 信息能最高效降低预测误差）。

在 RMSuon 中，我们首先利用 AdamW 的二阶矩机制来计算梯度的“能量”。这个能量场完美地编码了参数的统计特性和唯一性信息（Unique）。接着，我们使用 Muon 的正交化算子来处理梯度的“方向”。这个过程剔除了梯度中的冗余相关性，构建了一个纯净的几何流形。

最关键的一步发生了：我们将 AdamW 计算出的能量，重新注入到 Muon 产生的正交方向上。这不仅仅是数值上的缩放，而是协同（Synergy）的物理实现。协同信息定义为整体包含的、但不存在于任何单一部分的信息。在 RMSuon 中，正交化的几何结构提供了“去哪儿”的最优路径（最小化干扰），而能量场提供了“走多远”的最优步长（最大化信息获取）。

通过这种能量-几何解耦（Energy-Geometry Decoupling），RMSuon 实现了 Synergy 的涌现：它让参数更新既保持了全局的几何正交性，避免了冗余特征的同质化竞争；又保留了局部的统计独立性，确保了关键特征能够得到充分的表达。这不再是简单的“修正”，而是一种更高维度的综合，解释了为何 RMSuon 能够在保持 Muon 结构稳定性的同时，具备了超越 Muon 的学习效率。
