---
title: "ADR-0001: 基于训练时间尺度的自适应权重衰减"
status: "Rejected"
date: "2025-11-30"
authors: "Ω Researcher"
tags: ["optimizer", "regularization", "adaptive-hyperparameter"]
supersedes: ""
superseded_by: ""
---

# ADR-0001: 基于训练时间尺度的自适应权重衰减

## 否决原因 (Rejection Reason)

该方案基于一个核心假设：当前的 `weight_decay`（0.1）过弱，需要一个更强的、与训练时间尺度匹配的正则化。然而，通过离线脚本精确计算出的自适应 `λ*` 值为 `0.0055`，这比我们实验中使用的 `0.1` 小了一个数量级以上。

这一结果与我们的初始假设完全相反，它表明：

1. **问题不在于强度**：`RMSuon` 的过拟合问题并非源于权重衰减强度不足。即使是理论上“理想”的、强得多的 `wd=0.1` 也未能有效抑制过拟合。
2. **范式不匹配**：这进一步证实了 L2 权重衰减这种**基于范数的正则化**与 `RMSuon` **基于几何的优化动力学**之间存在根本性的不匹配。

因此，该方案被否决，因为它无法解决核心问题。我们需要探索与 `RMSuon` 优化范式更兼容的、非范数基础的正则化方法。

## 状态 (Status)

Proposed | Accepted | **Rejected** | Superseded | Deprecated

## 背景 (Context)

在对 `RMSuon` 优化器的实验中，我们观察到标准的权重衰减（`weight_decay`）机制未能有效防止模型在训练后期出现过拟合。初步实验（`wd=0.1` vs `wd=0.0`）显示，权重衰减对 `RMSuon` 的正则化效果微乎其微，表明需要一种更强的、或与优化器动力学更匹配的正则化策略。当前的权重衰减值是一个需要手动调整的超参数，缺乏理论依据，且无法适应不同的数据集规模和训练配置。

## 决策 (Decision)

我们决定提出并实施一种**基于训练时间尺度的自适应权重衰减**方案。该方案的核心思想是，将权重衰减率 `λ` 与训练的一个周期（epoch）内的迭代步数 `S` 关联起来，从而实现免调参的、与训练动力学同步的正则化。

其推导过程如下：

1. **设定衰减目标**：我们要求模型参数 `θ` 在无梯度更新的情况下，经过一个 epoch（即 `S` 步）后，其范数应衰减至一个极小比例 `ε`（例如 `1e-3`）。
2. **推导衰减率**：根据标准权重衰减公式 `θ_S = θ_0 * (1 - λ)^S`，我们解出 `λ = 1 - ε^(1/S)`。
3. **计算 `S`**：`S` 由训练集总样本数 `N` 和批大小 `B` 决定，即 `S = ceil(N / B)`。

该自适应权重衰减率 `λ` 将作为一个静态值，在训练开始前离线计算，并用于整个训练过程。

## 后果 (Consequences)

### 积极 (Positive)

- **POS-001**: **免调参（Hyperparameter-free）**：消除了手动调整 `weight_decay` 的需要，降低了实验成本和复杂性。
- **POS-002**: **时间尺度归一化（Time-Scale Normalization）**：正则化强度与训练集大小和批大小自动对齐，使得在不同训练配置下的正则化效应具有可比性。
- **POS-003**: **理论优雅性（Theoretical Elegance）**：该方案将正则化与训练过程的基本时间尺度（“遗忘周期”）联系起来，提供了一个比固定值更具第一性原理的解释。

### 消极 (Negative)

- **NEG-001**: **静态性限制（Static Limitation）**：计算出的 `λ` 在整个训练过程中是固定的，无法适应学习动态的变化（例如，在训练后期可能需要更强的正则化）。
- **NEG-002**: **不适用于持续学习（Inapplicable to Continual Learning）**：该方案假设一个固定的训练集和训练周期，因此无法直接应用于数据流永无止境的持续学习或在线学习场景。
- **NEG-003**: **有效性待验证（Effectiveness Unverified）**：虽然理论上优雅，但其在实践中是否能有效抑制 `RMSuon` 的过拟合，尚需通过实验验证。

## 考虑的备选方案 (Alternatives Considered)

### 信息瓶颈正则化 (Information Bottleneck Regularization)

- **ALT-001**: **描述 (Description)**: 将信息瓶颈理论的压缩项 `I(Z;X)` 作为正则化目标，并使用 `Adam` 的二阶矩之和 `Σ(v)` 作为其可计算的代理。
- **ALT-002**: **拒绝理由 (Rejection Reason)**: 该方案是一个未经证实的研究假设，其理论基础（`Σ(v) ≈ Tr(F) ≈ I(Z;X)`）较为薄弱，引入了过多的不确定性。在尝试更复杂的理论之前，应先验证更简单、更直接的方案。

### 固定权重衰减 (Fixed Weight Decay)

- **ALT-003**: **描述 (Description)**: 继续使用固定的、手动调整的 `weight_decay` 值。
- **ALT-004**: **拒绝理由 (Rejection Reason)**: 实验已证明，标准的 `wd` 值（如 `0.1` 或 `0.0`）对 `RMSuon` 效果不佳。寻找一个“最优”的固定值需要大量的网格搜索，成本高昂且缺乏通用性。

## 实施注意事项 (Implementation Notes)

- **IMP-001**: 需要创建一个离线脚本，该脚本读取数据集信息（总样本数 `N`）和配置文件（批大小 `B`），计算出自适应 `λ` 值。
- **IMP-002**: 在训练流程中，需要能够接收并使用这个离线计算出的 `λ` 值。
- **IMP-003**: 成功标准是通过对比实验来衡量。新的自适应 `wd` 方案应在保持或提高 `RMSuon` 早期收敛速度的同时，显著抑制其在训练后期的过拟合现象（即，在更长的 epoch 后获得更低的验证PPL）。

## 参考文献 (References)

- **REF-001**: `outputs/wikitext2_rope_rmsuon_wd0_epoch10/summary.md` (实验结果，表明 `wd=0` 与 `wd=0.1` 效果类似)
